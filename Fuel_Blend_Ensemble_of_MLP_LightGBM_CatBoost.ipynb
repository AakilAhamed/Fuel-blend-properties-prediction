{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBF6JsQ1FCm9zT3dDzfQiR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd91cf6a",
        "outputId": "5ad0f680-9d68-4581-8bd7-4d8393f29321"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df3329d0",
        "outputId": "6e36ea5d-7d36-46fe-8963-b036ce287a41"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to your zip file in Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/Datasets/ShellAiData.zip' # Replace with the actual path to your zip file\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extracted_path = '/content' # Replace with your desired extraction path\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extracted_path, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "print(f'Dataset extracted to {extracted_path}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm catboost --quiet"
      ],
      "metadata": {
        "id": "Tj4If58YMvlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "import joblib"
      ],
      "metadata": {
        "id": "StDFrdBSMxR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "a5SK3b14M3KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/train.csv')\n",
        "target_cols = [col for col in df.columns if 'Blend' in col]\n",
        "X = df.drop(columns=target_cols)\n",
        "y = df[target_cols]"
      ],
      "metadata": {
        "id": "ff_KCqQ1M6O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "5aztYxwtNB4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def engineer_features(df):\n",
        "    df = df.copy()\n",
        "    for col in df.columns:\n",
        "        if 'Property' in col or 'fraction' in col:\n",
        "            df[f'log_{col}'] = np.log1p(df[col])\n",
        "            df[f'sqrt_{col}'] = np.sqrt(df[col])\n",
        "    prop_cols = [c for c in df.columns if 'Property' in c]\n",
        "    df['prop_mean'] = df[prop_cols].mean(axis=1)\n",
        "    df['prop_std'] = df[prop_cols].std(axis=1)\n",
        "    return df\n",
        "\n",
        "X_fe = engineer_features(X)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_fe)"
      ],
      "metadata": {
        "id": "NxoxGQoyNEwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7CjI1bvsNPNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "6zbD0nSbNMrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch Dataset"
      ],
      "metadata": {
        "id": "DcQEOf_rNXdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FuelDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "train_ds = FuelDataset(X_train, y_train)\n",
        "val_ds = FuelDataset(X_val, y_val)\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32)"
      ],
      "metadata": {
        "id": "0N0e8fHqNafP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Model"
      ],
      "metadata": {
        "id": "0OM47zO8NeJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Linear(64, out_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "def mape_loss(pred, target):\n",
        "    return torch.mean(torch.abs((target - pred) / (target + 1e-8)))\n",
        "\n",
        "model = MLP(X_scaled.shape[1], y.shape[1])\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        pred = model(xb)\n",
        "        loss = mape_loss(pred, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = mape_loss(model(torch.tensor(X_val, dtype=torch.float32)), torch.tensor(y_val.values, dtype=torch.float32)).item()\n",
        "    print(f\"Epoch {epoch+1}, Val MAPE: {val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "OnIJnI0HNiSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LGBM"
      ],
      "metadata": {
        "id": "JuvXZLP5Np2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = LGBMRegressor(n_estimators=300, learning_rate=0.05)\n",
        "lgb_model.fit(X_scaled, y)\n",
        "lgb_preds = lgb_model.predict(X_scaled)"
      ],
      "metadata": {
        "id": "jkap2GZLNsH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CatBoost"
      ],
      "metadata": {
        "id": "yUW29y6gNxH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostRegressor(verbose=0, iterations=300, learning_rate=0.05)\n",
        "cat_model.fit(X_scaled, y)\n",
        "cat_preds = cat_model.predict(X_scaled)"
      ],
      "metadata": {
        "id": "rRm7IGo6N1Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Net prediction"
      ],
      "metadata": {
        "id": "c6-ouDzwN58u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "nn_preds = model(torch.tensor(X_scaled, dtype=torch.float32)).detach().numpy()"
      ],
      "metadata": {
        "id": "cIbBwaNQN9bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blend all three"
      ],
      "metadata": {
        "id": "AgCiaF9NOFT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_preds = (nn_preds + lgb_preds + cat_preds) / 3"
      ],
      "metadata": {
        "id": "sZekllGxOHPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict on test.csv"
      ],
      "metadata": {
        "id": "6u5sZRiYOPyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/test.csv')\n",
        "X_test_fe = engineer_features(test_df)[X_fe.columns]\n",
        "X_test_scaled = scaler.transform(X_test_fe)\n",
        "\n",
        "nn_test_preds = model(torch.tensor(X_test_scaled, dtype=torch.float32)).detach().numpy()\n",
        "lgb_test_preds = lgb_model.predict(X_test_scaled)\n",
        "cat_test_preds = cat_model.predict(X_test_scaled)\n",
        "test_preds = (nn_test_preds + lgb_test_preds + cat_test_preds) / 3"
      ],
      "metadata": {
        "id": "lqiogYc8OXz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save submission"
      ],
      "metadata": {
        "id": "K1vPdnYrOdkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame(test_preds, columns=y.columns)\n",
        "submission.to_csv(\"/content/final-solution.csv\", index=True)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/final-solution-ensemble-mlp-lgmb-cat.csv\")"
      ],
      "metadata": {
        "id": "CjVaCQSBOe8l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}